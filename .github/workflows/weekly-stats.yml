name: Weekly Actions Statistics Collection
on:
  schedule:
    # æ¯é€±æœˆæ›œæ—¥ åˆå‰2æ™‚30åˆ† (UTC) ã«å®Ÿè¡Œ
    - cron: '30 2 * * 1'
  workflow_dispatch: # æ‰‹å‹•å®Ÿè¡Œå¯èƒ½

permissions:
  contents: write
  pull-requests: write
  actions: read

jobs:
  collect-stats:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Create GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.APP_PRIVATE_KEY }}
          permission-pull-requests: write
      
      - name: Set date range
        run: |
          echo "START_DATE=$(date -d '7 days ago' +%Y-%m-%d)" >> $GITHUB_ENV
          echo "END_DATE=$(date +%Y-%m-%d)" >> $GITHUB_ENV
          echo "REPORT_DATE=$(date +%Y%m%d)" >> $GITHUB_ENV
      
      - name: Collect workflow statistics
        run: |
          set -euo pipefail
          
          # å…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å–å¾—
          echo "Fetching workflows..."
          gh api repos/${{ github.repository }}/actions/workflows > all_workflows.json
          
          # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
          echo "[]" > weekly_stats.json
          
          # å„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å‡¦ç†
          jq -c '.workflows[]' all_workflows.json | while IFS= read -r workflow; do
            id=$(echo "$workflow" | jq -r '.id')
            name=$(echo "$workflow" | jq -r '.name')
            
            echo "Processing workflow: $name (ID: $id)"
            
            # å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            echo > "runs_$id.json"
            page=1
            while true; do
              response=$(gh api "repos/${{ github.repository }}/actions/workflows/$id/runs?page=$page&per_page=100" || echo '{"workflow_runs":[]}')
              runs=$(echo "$response" | jq "[.workflow_runs[] | select(.created_at >= \"$START_DATE\" and .created_at <= \"$END_DATE\")]")
              
              if [ "$(echo "$runs" | jq 'length')" -eq 0 ]; then
                break
              fi
              
              echo "$runs" | jq -c '.[]' >> "runs_$id.json"
              ((page++))
            done
            
            # çµ±è¨ˆã‚’è¨ˆç®—
            if [ -s "runs_$id.json" ]; then
              echo "Calculating statistics for $name..."
              
              # Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦å®Ÿè¡Œ
              cat > calculate_stats.py << 'EOF'
          import json
          import sys
          from datetime import datetime

          workflow_id = sys.argv[1]
          workflow_name = sys.argv[2]
          start_date = sys.argv[3]
          end_date = sys.argv[4]

          runs = []
          with open(f'runs_{workflow_id}.json', 'r') as f:
              for line in f:
                  if line.strip():
                      runs.append(json.loads(line))

          stats = {
              'workflow_name': workflow_name,
              'workflow_id': int(workflow_id),
              'period': {
                  'start': start_date,
                  'end': end_date
              },
              'total_runs': len(runs),
              'success_count': sum(1 for r in runs if r.get('conclusion') == 'success'),
              'failure_count': sum(1 for r in runs if r.get('conclusion') == 'failure'),
              'cancelled_count': sum(1 for r in runs if r.get('conclusion') == 'cancelled'),
          }

          stats['success_rate'] = (stats['success_count'] / stats['total_runs'] * 100) if stats['total_runs'] > 0 else 0
          stats['failure_rate'] = (stats['failure_count'] / stats['total_runs'] * 100) if stats['total_runs'] > 0 else 0

          # å¹³å‡å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
          durations = []
          for run in runs:
              if run.get('conclusion') == 'success' and run.get('run_started_at') and run.get('updated_at'):
                  try:
                      start = datetime.fromisoformat(run['run_started_at'].replace('Z', '+00:00'))
                      end = datetime.fromisoformat(run['updated_at'].replace('Z', '+00:00'))
                      durations.append((end - start).total_seconds())
                  except:
                      pass

          stats['avg_duration_seconds'] = sum(durations) / len(durations) if durations else 0
          stats['last_run_at'] = max((r.get('created_at') for r in runs), default=None)

          print(json.dumps(stats))
          EOF
              
              python3 calculate_stats.py "$id" "$name" "$START_DATE" "$END_DATE" > temp_stat.json
              rm -f calculate_stats.py
              
              # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
              jq -s '.[0] + [.[1]]' weekly_stats.json temp_stat.json > updated_stats.json
              mv updated_stats.json weekly_stats.json
              rm -f temp_stat.json
            else
              echo "No runs found for $name in the specified period"
            fi
            
            rm -f "runs_$id.json"
          done
          
          # æœ€çµ‚çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
          jq "{
            generated_at: (now | strftime(\"%Y-%m-%dT%H:%M:%SZ\")),
            repository: \"${{ github.repository }}\",
            statistics: .
          }" weekly_stats.json > final_stats.json
          
          echo "Statistics collection completed successfully"
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
      
      - name: Update actions-log.json
        run: |
          # actions-log.jsonãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°ã¾ãŸã¯ä½œæˆ
          if [ -f "actions-log.json" ]; then
            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            jq --argjson new_data "$(cat final_stats.json)" '. + [$new_data]' actions-log.json > updated_log.json
            mv updated_log.json actions-log.json
          else
            # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            jq -s '.' final_stats.json > actions-log.json
          fi
          
          # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆæœ€æ–°50ã‚¨ãƒ³ãƒˆãƒªã¾ã§ä¿æŒï¼‰
          jq '.[(-50):]' actions-log.json > temp_log.json
          mv temp_log.json actions-log.json
          
          # èª­ã¿ã‚„ã™ã„å½¢å¼ã§æ•´ç†
          jq --indent 2 '.' actions-log.json > formatted_log.json
          mv formatted_log.json actions-log.json
      
      - name: Create detailed report
        run: |
          cat << 'EOF' > weekly_report.md
          # é€±æ¬¡ GitHub Actions çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
          
          **ãƒ¬ãƒãƒ¼ãƒˆä½œæˆæ—¥**: $(date '+%Yå¹´%mæœˆ%dæ—¥')  
          **å¯¾è±¡æœŸé–“**: $START_DATE ã‹ã‚‰ $END_DATE ã¾ã§
          
          ## çµ±è¨ˆã‚µãƒãƒªãƒ¼
          
          | ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å | å®Ÿè¡Œå›æ•° | æˆåŠŸç‡ | å¤±æ•—ç‡ | å¹³å‡å®Ÿè¡Œæ™‚é–“(ç§’) | æœ€çµ‚å®Ÿè¡Œæ—¥ |
          |---|---|---|---|---|---|
          EOF
          
          # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
          cat final_stats.json | jq -r '
            .statistics[] | 
            "| \(.workflow_name) | \(.total_runs) | \(.success_rate | tostring | .[0:5])% | \(.failure_rate | tostring | .[0:5])% | \(.avg_duration_seconds | tostring | .[0:6]) | \(.last_run_at // "N/A") |"
          ' >> weekly_report.md
          
          cat << 'EOF' >> weekly_report.md
          
          ## è©³ç´°åˆ†æ
          
          ### æˆåŠŸç‡ãŒ90%æœªæº€ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
          EOF
          
          # å•é¡Œã®ã‚ã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç‰¹å®š
          cat final_stats.json | jq -r '
            .statistics[] | 
            select(.success_rate < 90 and .total_runs > 0) | 
            "- **\(.workflow_name)**: æˆåŠŸç‡ \(.success_rate | tostring | .[0:5])% (\(.success_count)/\(.total_runs) å›æˆåŠŸ)"
          ' >> weekly_report.md
          
          echo "" >> weekly_report.md
          echo "### å®Ÿè¡Œæ™‚é–“ãŒé•·ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ (60ç§’ä»¥ä¸Š)" >> weekly_report.md
          
          cat final_stats.json | jq -r '
            .statistics[] | 
            select(.avg_duration_seconds > 60) | 
            "- **\(.workflow_name)**: å¹³å‡å®Ÿè¡Œæ™‚é–“ \(.avg_duration_seconds | tostring | .[0:6]) ç§’"
          ' >> weekly_report.md
          
          # å¤‰æ•°ã®å±•é–‹
          envsubst < weekly_report.md > final_report.md
          mv final_report.md weekly_report.md
      
      - name: Create pull request
        id: create-pr
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ steps.app-token.outputs.token }}
          commit-message: "chore: update weekly actions statistics (${{ env.REPORT_DATE }})"
          title: "ğŸ“Š é€±æ¬¡ Actions çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ - ${{ env.REPORT_DATE }}"
          body-path: weekly_report.md
          branch: actions-stats-${{ env.REPORT_DATE }}
          delete-branch: true
          labels: |
            automation
            statistics
            actions
          assignees: ${{ github.repository_owner }}
          reviewers: ${{ github.repository_owner }}
      
      - name: Auto-merge pull request
        if: steps.create-pr.outputs.pull-request-number
        run: |
          # çŸ­ã„å¾…æ©Ÿå¾Œã«ãƒãƒ¼ã‚¸å®Ÿè¡Œ
          sleep 10
          
          # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è‡ªå‹•ãƒãƒ¼ã‚¸ã‚’æœ‰åŠ¹åŒ–
          gh pr merge ${{ steps.create-pr.outputs.pull-request-number }} \
            --auto \
            --squash \
            --delete-branch
          
          echo "Auto-merge enabled for PR #${{ steps.create-pr.outputs.pull-request-number }}"
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
      
      - name: Cleanup temporary files
        if: always()
        run: |
          rm -f workflows.json runs_*.json final_stats.json weekly_stats.json temp_stat.json
          echo "Cleanup completed"
